digraph {
	graph [size="18.3,18.3"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140485249149664 [label="
 (1, 42)" fillcolor=darkolivegreen1]
	140485698359248 [label=SqueezeBackward1]
	140482751437888 -> 140485698359248
	140482751437888 [label=ViewBackward0]
	140482644366048 -> 140482751437888
	140482644366048 [label=AddmmBackward0]
	140482761187968 -> 140482644366048
	140485249685520 [label="decoder.6.bias
 (42)" fillcolor=lightblue]
	140485249685520 -> 140482761187968
	140482761187968 [label=AccumulateGrad]
	140485248976208 -> 140482644366048
	140485248976208 [label=ViewBackward0]
	140482751049392 -> 140485248976208
	140482751049392 [label=ReluBackward0]
	140482751070608 -> 140482751049392
	140482751070608 [label=CudnnBatchNormBackward0]
	140482753525792 -> 140482751070608
	140482753525792 [label=ConvolutionBackward0]
	140482753606320 -> 140482753525792
	140482753606320 [label=ReluBackward0]
	140482753606992 -> 140482753606320
	140482753606992 [label=CudnnBatchNormBackward0]
	140482753608240 -> 140482753606992
	140482753608240 [label=ConvolutionBackward0]
	140482753609392 -> 140482753608240
	140482753609392 [label=SqueezeBackward1]
	140482753606368 -> 140482753609392
	140482753606368 [label=MaxPool2DWithIndicesBackward0]
	140482753608672 -> 140482753606368
	140482753608672 [label=UnsqueezeBackward0]
	140482753606752 -> 140482753608672
	140482753606752 [label=ReluBackward0]
	140482753607184 -> 140482753606752
	140482753607184 [label=CudnnBatchNormBackward0]
	140482753606512 -> 140482753607184
	140482753606512 [label=ConvolutionBackward0]
	140482753607904 -> 140482753606512
	140482753607904 [label=SqueezeBackward1]
	140482753606560 -> 140482753607904
	140482753606560 [label=MaxPool2DWithIndicesBackward0]
	140482753607328 -> 140482753606560
	140482753607328 [label=UnsqueezeBackward0]
	140482753609680 -> 140482753607328
	140482753609680 [label=ReluBackward0]
	140482753607856 -> 140482753609680
	140482753607856 [label=CudnnBatchNormBackward0]
	140482753608960 -> 140482753607856
	140482753608960 [label=ConvolutionBackward0]
	140482753608816 -> 140482753608960
	140485249587536 [label="encoder.0.weight
 (64, 1, 3)" fillcolor=lightblue]
	140485249587536 -> 140482753608816
	140482753608816 [label=AccumulateGrad]
	140482753607520 -> 140482753608960
	140482789903952 [label="encoder.0.bias
 (64)" fillcolor=lightblue]
	140482789903952 -> 140482753607520
	140482753607520 [label=AccumulateGrad]
	140482753609008 -> 140482753607856
	140482750907232 [label="encoder.1.weight
 (64)" fillcolor=lightblue]
	140482750907232 -> 140482753609008
	140482753609008 [label=AccumulateGrad]
	140482753609152 -> 140482753607856
	140485250998496 [label="encoder.1.bias
 (64)" fillcolor=lightblue]
	140485250998496 -> 140482753609152
	140482753609152 [label=AccumulateGrad]
	140482753606800 -> 140482753606512
	140485249686960 [label="encoder.4.weight
 (32, 64, 3)" fillcolor=lightblue]
	140485249686960 -> 140482753606800
	140482753606800 [label=AccumulateGrad]
	140482753607472 -> 140482753606512
	140485249687280 [label="encoder.4.bias
 (32)" fillcolor=lightblue]
	140485249687280 -> 140482753607472
	140482753607472 [label=AccumulateGrad]
	140482753608864 -> 140482753607184
	140485249685760 [label="encoder.5.weight
 (32)" fillcolor=lightblue]
	140485249685760 -> 140482753608864
	140482753608864 [label=AccumulateGrad]
	140482753606464 -> 140482753607184
	140485249686160 [label="encoder.5.bias
 (32)" fillcolor=lightblue]
	140485249686160 -> 140482753606464
	140482753606464 [label=AccumulateGrad]
	140482753608432 -> 140482753608240
	140485249685840 [label="decoder.0.weight
 (32, 64, 2)" fillcolor=lightblue]
	140485249685840 -> 140482753608432
	140482753608432 [label=AccumulateGrad]
	140482753608336 -> 140482753608240
	140485249683920 [label="decoder.0.bias
 (64)" fillcolor=lightblue]
	140485249683920 -> 140482753608336
	140482753608336 [label=AccumulateGrad]
	140482753607952 -> 140482753606992
	140485250998656 [label="decoder.1.weight
 (64)" fillcolor=lightblue]
	140485250998656 -> 140482753607952
	140482753607952 [label=AccumulateGrad]
	140482753608624 -> 140482753606992
	140485251002256 [label="decoder.1.bias
 (64)" fillcolor=lightblue]
	140485251002256 -> 140482753608624
	140482753608624 [label=AccumulateGrad]
	140482753607136 -> 140482753525792
	140485249684640 [label="decoder.3.weight
 (64, 1, 2)" fillcolor=lightblue]
	140485249684640 -> 140482753607136
	140482753607136 [label=AccumulateGrad]
	140482753608192 -> 140482753525792
	140485249683840 [label="decoder.3.bias
 (1)" fillcolor=lightblue]
	140485249683840 -> 140482753608192
	140482753608192 [label=AccumulateGrad]
	140482753527040 -> 140482751070608
	140485249683680 [label="decoder.4.weight
 (1)" fillcolor=lightblue]
	140485249683680 -> 140482753527040
	140482753527040 [label=AccumulateGrad]
	140482753526176 -> 140482751070608
	140485249685120 [label="decoder.4.bias
 (1)" fillcolor=lightblue]
	140485249685120 -> 140482753526176
	140482753526176 [label=AccumulateGrad]
	140485248978560 -> 140482644366048
	140485248978560 [label=TBackward0]
	140482751070944 -> 140485248978560
	140485249685360 [label="decoder.6.weight
 (42, 84)" fillcolor=lightblue]
	140485249685360 -> 140482751070944
	140482751070944 [label=AccumulateGrad]
	140485698359248 -> 140485249149664
	140482753041568 [label="
 (1, 42)" fillcolor=darkolivegreen3]
	140482644366048 -> 140482753041568
	140482753041568 -> 140485249149664 [style=dotted]
}
